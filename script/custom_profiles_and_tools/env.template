OPENAI_API_KEY= your_api_key_here
MODEL_NAME="gpt-realtime"

# Local vision model (only used with --local-vision CLI flag)
# By default, vision is handled by gpt-realtime when the camera tool is used
LOCAL_VISION_MODEL=HuggingFaceTB/SmolVLM2-2.2B-Instruct

# Cache for local VLM (only used with --local-vision CLI flag)
HF_HOME=./cache

# Hugging Face token for accessing datasets/models
HF_TOKEN= your_token_here

# To select a specific profile with custom instructions and tools, to be placed in profiles/<myprofile>/__init__.py
REACHY_MINI_CUSTOM_PROFILE="custom_profile"
# To point to the directory containing the custom profile
PROFILES_DIRECTORY= /path/to/script/custom_profiles_and_tools
# To point to the directory containing the custom tools
TOOLS_DIRECTORY= /path/to/script/custom_profiles_and_tools/custom_tool